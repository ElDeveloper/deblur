#!/usr/bin/env python

# ----------------------------------------------------------------------------
# Copyright (c) 2015, The Deblur Development Team.
#
# Distributed under the terms of the BSD 3-clause License.
#
# The full license is in the file LICENSE, distributed with this software.
# ----------------------------------------------------------------------------

import click
from os.path import exists, split
from os import makedirs, mkdir
from os.path import join
from glob import glob
from shutil import rmtree
import logging

from skbio.util import remove_files

from deblur.parallel_deblur import parallel_deblur
from deblur.workflow import (split_sequence_file_on_sample_ids_to_files,
                             start_log,
                             build_index_sortmerna)


@click.group()
def parallel_deblur_cmds():
    pass


# LAUNCH FULL DEBLUR PIPELINE COMMAND
@parallel_deblur_cmds.command()
@click.option('--seqs-fp', required=True,
              type=click.Path(resolve_path=True, readable=True, exists=True,
                              file_okay=True),
              help="Demultiplexed FASTA/Q file including all samples")
@click.option('--output-dir', required=True,
              type=click.Path(resolve_path=True, readable=True, exists=False,
                              dir_okay=True),
              help="Directory path to store output including BIOM table")
@click.option('--ref-fp', required=True, multiple=True,
              type=click.Path(resolve_path=True, readable=True, exists=True,
                              file_okay=True),
              help="Keep all sequences aligning to this FASTA database "
                   "(for multiple databases, use "
                   "--ref-fp db1.fa --ref-fp db2.fa ..)")
@click.option('--ref-db-fp', required=False, multiple=True,
              type=click.Path(resolve_path=True, readable=True, exists=False,
                              file_okay=True),
              help="Keep all sequences aligning to this indexed "
                   "database. For multiple databases, the order "
                   "must follow that of --ref-fp, for example, "
                   "--ref-db-fp db1.idx --ref-db-fp db2.idx ..")
@click.option('--overwrite', '-w', required=False, type=bool, default=False,
              show_default=True, help="Overwrite output directory if exists.")
@click.option('--read-error', '-e', required=False, type=float, default=0.05,
              show_default=True, help="Read error rate")
@click.option('--mean-error', '-m', required=False, type=float, default=0.005,
              show_default=True,
              help="The mean error, used for original sequence estimate. If "
                   "not passed the same value as --read-error will be used")
@click.option('--error-dist', '-d', required=False, type=str, default=None,
              show_default=True,
              help="A comma separated list of error probabilities for each "
                   "hamming distance. The length of the list determines the "
                   "number of hamming distances taken into account.")
@click.option('--indel-prob', '-i', required=False, type=float, default=0.01,
              show_default=True,
              help='Insertion/deletion (indel) probability '
                   '(same for N indels)')
@click.option('--indel-max', required=False, type=int, default=3,
              show_default=True,
              help="Maximal indel number")
@click.option('--trim-length', '-t', required=False, type=int, default=100,
              show_default=True, help="Sequence trim length")
@click.option('--min-size', required=False, type=int, default=2,
              show_default=True, help="Discard sequences with an abundance "
              "value smaller than min-size")
@click.option('--negate', '-n', required=False, default=False,
              show_default=True, type=bool,
              help="Discard all sequences aligning to the database "
                   "passed via --ref-fp option")
@click.option('--delim', required=False, type=str, default='_',
              show_default=True, help="Delimiter in FASTA labels to separate "
                                      "sample ID from sequence ID")
@click.option('--jobs-to-start', '-O', required=False, type=int, default=1,
              show_default=True,
              help="Number of jobs to start (if to run in parallel)")
@click.option('--keep-tmp-files', required=False, type=bool, default=False,
              show_default=True,
              help="Keep temporary files (useful for debugging)")
@click.option('--log-level', required=False, type=click.IntRange(1, 5, clamp=True), default=2,
              show_default=True, help="Level of messages for log file"
              "(range 1-debug to 5-critical")
@click.option('--log-file', required=False, type=click.Path(resolve_path=True, readable=True, exists=False,
              dir_okay=True), default='deblur.log',
              show_default=True, help="log file name")
@click.option('attack_mode', '-A', required=False, type=bool, default=False,
              help="ATTACK MODE (http://xkcd.com/1692)")
def workflow(seqs_fp, output_dir, ref_fp, ref_db_fp, overwrite,
             read_error, mean_error, error_dist, indel_prob, indel_max,
             trim_length, min_size, negate, delim, jobs_to_start,
             keep_tmp_files,log_level,log_file):
    """Launch deblur workflow in parallel"""
    # If the user provided an error_dist value, we map it to a list of floats
    start_log(level=log_level * 10, filename=log_file)
    logger = logging.getLogger(__name__)
    logger.info('deblur version %s workflow started on %s' % (__version__, seqs_fp))
    logger.info('parameters: %s' % locals())

    if error_dist:
        error_dist = list(map(float, error_dist.split(',')))
    # Create output directory
    if exists(output_dir):
        if overwrite:
            rmtree(output_dir)
        else:
            raise OSError("Output directory already exists. Choose a "
                          "different directory or use option --overwrite True"
                          "(-w True)")
    mkdir(output_dir)
    # Split demultiplexed FASTA on sample IDs
    out_dir_split = join(output_dir, "split")
    mkdir(out_dir_split)
    with open(seqs_fp, 'U') as seqs_f:
        split_sequence_file_on_sample_ids_to_files(
            seqs_f,
            out_dir_split)
    # Build SortMeRNA indexes
    files_to_remove = []

    if not ref_db_fp:
        logger.info('building sortmerna index files')
        ref_db_fp = build_index_sortmerna(
            ref_fp=ref_fp,
            working_dir=output_dir)

    # Run deblur in parallel
    params = {}
    input_fps = glob('%s/*' % out_dir_split)
    params['output-dir'] = output_dir
    params['ref-db-fp'] = ref_db_fp
    params['ref-fp'] = ref_fp
    params['read-error'] = read_error
    params['mean-error'] = mean_error
    params['error-dist'] = error_dist
    params['indel-prob'] = indel_prob
    params['indel-max'] = indel_max
    params['trim-length'] = trim_length
    params['min-size'] = min_size
    params['negate'] = negate
    params['delim'] = delim
    all_bioms = parallel_deblur(input_fps, params, jobs_to_start)
    # Merge OTU tables
    output_fp = join(output_dir, "final.biom")
#    merge_otu_tables(output_fp, all_bioms)
    # Clean up
    if not keep_tmp_files:
        remove_files(files_to_remove, error_on_missing=False)
        for f in all_bioms:
            tmp_dir = split(f)[0]
            rmtree(tmp_dir)


if __name__ == '__main__':
    parallel_deblur_cmds()
