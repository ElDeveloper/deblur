#!/usr/bin/env python

# ----------------------------------------------------------------------------
# Copyright (c) 2015, The Deblur Development Team.
#
# Distributed under the terms of the BSD 3-clause License.
#
# The full license is in the file LICENSE, distributed with this software.
# ----------------------------------------------------------------------------

import click
from os import listdir, makedirs, mkdir
from os.path import join, isfile, exists
from shutil import rmtree
import logging

from skbio.parse.sequences import parse_fasta
from skbio.util import remove_files

from deblur.deblurring import deblur
from deblur.workflow import (launch_workflow, trim_seqs, dereplicate_seqs,
                             remove_artifacts_seqs,
                             multiple_sequence_alignment,
                             remove_chimeras_denovo_from_seqs,
                             split_sequence_file_on_sample_ids_to_files,
                             build_index_sortmerna,
                             get_files_for_table,
                             create_otu_table,
                             start_log)


__version__ = "0.9.2.1"


@click.group()
def deblur_cmds():
    start_log()


# DEBLUR SEQUENCES COMMAND
@deblur_cmds.command()
@click.argument('seqs_fp', required=True,
                type=click.Path(resolve_path=True, readable=True, exists=True,
                                file_okay=True))
@click.option('--read-error', '-e', required=False, type=float, default=0.05,
              help="Maximal bound on 1 nucleotide read error rate")
@click.option('--mean-error', '-m', required=False, type=float, default=0.005,
              help="The mean per nucleotide error, used for original "
              "sequence estimate. If "
              "not passed typical illumina error rate is used")
@click.option('--error-dist', '-d', required=False, type=str, default=None,
              help="A comma separated list of error probabilities for each "
                   "hamming distance. The length of the list determines the "
                   "number of hamming distances taken into account.")
@click.option('--indel-prob', '-i', required=False, type=float, default=0.01,
              help='Insertion/deletion (indel) probability '
                   '(same for N indels)')
@click.option('--indel-max', required=False, type=int, default=3,
              help="Maximal indel number")
def deblur_seqs(seqs_fp, read_error, mean_error, error_dist, indel_prob,
                indel_max):
    """Clean read errors from Illumina reads"""
    logger = logging.getLogger(__name__)
    logger.info('deblur deblur_seqs started on file %s' % seqs_fp)

    # If the user provided an error_dist value, we map it to a list of floats
    if error_dist:
        error_dist = list(map(float, error_dist.split(',')))

    with open(seqs_fp, 'U') as f:
        seqs = deblur(parse_fasta(f), read_error, mean_error, error_dist,
                      indel_prob, indel_max)

    output_path = "%s.clean" % seqs_fp
    with open(output_path, 'w') as f:
        for s in seqs:
            f.write(s.to_fasta())


# TRIM LENGTH COMMAND
@deblur_cmds.command()
@click.argument('seqs_fp', required=True,
                type=click.Path(resolve_path=True, readable=True, exists=True,
                                file_okay=True))
@click.argument('output_fp', required=True,
                type=click.Path(resolve_path=True, readable=True, exists=False,
                                file_okay=True))
@click.option('--trim-length', '-t', required=False, type=int, default=100,
              help="Sequence trim length")
def trim(seqs_fp, output_fp, trim_length):
    """Trim FASTA sequences"""
    logger = logging.getLogger(__name__)
    logger.info('deblur deblur_seqs started on file %s' % seqs_fp)
    with open(seqs_fp, 'U') as in_f, open(output_fp, 'w') as out_f:
        for label, seq in trim_seqs(parse_fasta(in_f), trim_length):
            out_f.write(">%s\n%s\n" % (label, seq))


# SEQUENCE DEREPLICATION/SINGLETON REMOVAL COMMAND
@deblur_cmds.command()
@click.argument('seqs_fp', required=True,
                type=click.Path(resolve_path=True, readable=True, exists=True,
                                file_okay=True))
@click.argument('output_fp', required=True,
                type=click.Path(resolve_path=True, readable=True, exists=False,
                                file_okay=True))
@click.option('--min-size', required=False, type=int, default=2,
              show_default=True, help="Discard sequences with an abundance "
              "value smaller than min-size")
def dereplicate(seqs_fp, output_fp, min_size):
    """
    Dereplicate FASTA sequences.

    Dereplicate input FASTA sequences and remove clusters
    with fewer than minimum number of occurrences (set by --min-size).
    """
    dereplicate_seqs(seqs_fp=seqs_fp,
                     output_fp=output_fp,
                     min_size=min_size)


# ARTIFACT REMOVAL COMMAND
@deblur_cmds.command()
@click.argument('seqs_fp', required=True,
                type=click.Path(resolve_path=True, readable=True, exists=True,
                                file_okay=True))
@click.argument('output_dir', required=True,
                type=click.Path(resolve_path=True, readable=True, exists=False,
                                file_okay=True))
@click.option('--ref-fp', required=True, multiple=True,
              type=click.Path(resolve_path=True, readable=True, exists=False,
                              file_okay=True),
              help="Keep all sequences aligning to this FASTA database "
                   "(for multiple databases, use "
                   "--ref-fp db1.fa --ref-fp db2.fa ..)")
@click.option('--ref-db-fp', required=False, multiple=True,
              type=click.Path(resolve_path=True, readable=True, exists=False,
                              file_okay=True),
              help="Keep all sequences aligning to this indexed "
                   "database. For multiple databases, the order "
                   "must follow that of --ref-fp, for example, "
                   "--ref-db-fp db1.idx --ref-db-fp db2.idx ..")
@click.option('--negate', '-n', required=False, default=False,
              show_default=True, type=bool,
              help="Discard all sequences aligning to the database "
                   "passed via --ref-fp option")
@click.option('--threads-per-sample', '-t', required=False, type=int,
              default=1, show_default=True,
              help="Number of threads to use per sample")
def remove_artifacts(seqs_fp, output_dir, ref_fp, ref_db_fp,
                     negate, threads_per_sample):
    """
    Filter artifacts.

    Filter artifacts from input sequences based on database(s)
    provided with the --ref-fp (raw FASTA file) or
    --ref-db-fp (indexed database) options.
    """
    logger = logging.getLogger(__name__)
    logger.info('---------------------------------')
    logger.info('remove_artifacts')
    logger.info('number of database files %d' % len(ref_fp))
    if ref_db_fp:
        if len(ref_fp) != len(ref_db_fp):
            logger.critical("The number of FASTA reference databases "
                            "does not match the number of indexed "
                            "reference databases")
            raise ValueError("The number of FASTA reference databases "
                             "does not match the number of indexed "
                             "reference databases")
    else:
        logger.warn('sortmerna database does not exist, '
                    'creating it into dir %s' % output_dir)
        ref_db_fp = build_index_sortmerna(
            ref_fp=ref_fp,
            working_dir=output_dir)

    remove_artifacts_seqs(seqs_fp=seqs_fp,
                          ref_fp=ref_fp,
                          working_dir=output_dir,
                          ref_db_fp=ref_db_fp,
                          negate=negate,
                          threads=threads_per_sample)


# INDEX ARTIFACT DB COMMAND
@deblur_cmds.command()
@click.argument('ref_fp', required=True,
                type=click.Path(resolve_path=True, readable=True, exists=False,
                                file_okay=True))
@click.argument('output_dir', required=True,
                type=click.Path(resolve_path=True, readable=True, exists=False,
                                file_okay=True))
def build_db_index(ref_fp,output_dir):
    """
    Preapare the artifacts database

    Input:
    ref_fp - the fasta sequence database for artifact removal
    output_dir - the directory to where to write the indexed database
    """
    logger = logging.getLogger(__name__)
    logger.info('---------------------------------')
    logger.info('build_db_index')
    logger.info('for database file %s, into dir %s' % (ref_fp,output_dir))
    build_index_sortmerna(ref_fp=[ref_fp], working_dir=output_dir)
    logger.info('done build_db_index')


# MULTIPLE SEQUENCE ALIGNMENT COMMAND
@deblur_cmds.command()
@click.argument('seqs_fp', required=True,
                type=click.Path(resolve_path=True, readable=True, exists=True,
                                file_okay=True))
@click.argument('output_fp', required=True,
                type=click.Path(resolve_path=True, readable=True, exists=False,
                                file_okay=True))
@click.option('--threads-per-sample', '-a', required=False, type=int,
              default=1, show_default=True,
              help="Number of threads to use per sample")
def multiple_seq_alignment(seqs_fp, output_fp, threads_per_sample):
    """Multiple sequence alignment"""
    alignment = multiple_sequence_alignment(seqs_fp, threads=threads_per_sample)

    with open(output_fp, 'w') as f:
        f.write(alignment.to_fasta())


# DE NOVO CHIMERA REMOVAL COMMAND
@deblur_cmds.command()
@click.argument('seqs_fp', required=True,
                type=click.Path(resolve_path=True, readable=True, exists=True,
                                file_okay=True))
@click.argument('output_fp', required=True,
                type=click.Path(resolve_path=True, readable=True,
                                exists=False, file_okay=True))
def remove_chimeras_denovo(seqs_fp, output_fp):
    """Remove chimeras de novo using UCHIME (VSEARCH implementation)"""
    remove_chimeras_denovo_from_seqs(seqs_fp, output_fp)


# GENERATE BIOM TABLE COMMAND
@deblur_cmds.command()
@click.argument('seqs_fp', required=True,
                type=click.Path(resolve_path=True, readable=True, exists=True,
                                file_okay=True))
@click.argument('output_biom_fp', required=True,
                type=click.Path(resolve_path=True, readable=True, exists=False,
                                file_okay=True))
@click.argument('file_type', required=False, type=str, default='.fasta.trim.derep.no_artifacts.msa.deblur.no_chimeras')
def build_biom_table(seqs_fp, output_biom_fp,file_type):
    """Generate a BIOM table from a directory of chimera removed fasta files
    Parameters
    ----------
    seqs_fp : str
      the path to the directory containing the chimera removed fasta files
    output_biom_fp : str
      the path where to save the output biom table file ('final.biom')
    file_type : str
      the files type to add to the table
      (default='.trim.derep.no_artifacts.msa.deblur.no_chimeras',
      can be '.fasta' or '.fa' if needed)
    """
    output_filename = 'final.biom'
    output_fp = join(output_biom_fp, output_filename)

    samples = get_files_for_table(seqs_fp, file_type)
    create_otu_table(output_fp, samples)


# LAUNCH FULL DEBLUR PIPELINE COMMAND
@deblur_cmds.command()
@click.option('--seqs-fp', required=True,
              type=click.Path(resolve_path=True, readable=True, exists=True,
                              file_okay=True, dir_okay=True),
              help="Demultiplexed FASTA file including all samples")
@click.option('--output-dir', required=True,
              type=click.Path(resolve_path=True, readable=True, exists=False,
                              dir_okay=True),
              help="Directory path to store output including BIOM table")
@click.option('--ref-fp', required=True, multiple=True,
              type=click.Path(resolve_path=True, readable=True, exists=True,
                              file_okay=True),
              help="Keep all sequences aligning to this FASTA database "
                   "(for multiple databases, use "
                   "--ref-fp db1.fa --ref-fp db2.fa ..)")
@click.option('--ref-db-fp', required=False, multiple=True,
              type=click.Path(resolve_path=True, readable=True, exists=False,
                              file_okay=True),
              help="Keep all sequences aligning to this indexed "
                   "database. For multiple databases, the order "
                   "must follow that of --ref-fp, for example, "
                   "--ref-db-fp db1.idx --ref-db-fp db2.idx ..")
@click.option('--overwrite', '-w', required=False, type=bool, default=False,
              show_default=True, help="Overwrite output directory if exists.")
@click.option('--read-error', '-e', required=False, type=float, default=0.05,
              show_default=True,
              help="Maximal bound on 1 nucleotide read error rate."
                   "Required if --eror-dist is not supplied")
@click.option('--mean-error', '-m', required=False, type=float, default=0.005,
              show_default=True,
              help="The mean per nucleotide error, used for original sequence estimate. If "
                   "not passed typical illumina error rate is used")
@click.option('--error-dist', '-d', required=False, type=str, default=None,
              show_default=True,
              help="A comma separated list of error probabilities for each "
                   "hamming distance. The length of the list determines the "
                   "number of hamming distances taken into account. "
                   "This replaces of the --read-error value")
@click.option('--indel-prob', '-i', required=False, type=float, default=0.01,
              show_default=True,
              help='Insertion/deletion (indel) probability '
                   '(same for N indels)')
@click.option('--indel-max', required=False, type=int, default=3,
              show_default=True,
              help="Maximal indel number")
@click.option('--trim-length', '-t', required=False, type=int, default=100,
              show_default=True, help="Sequence trim length")
@click.option('--min-size', required=False, type=int, default=2,
              show_default=True, help="Discard sequences with an abundance "
              "value smaller than min-size")
@click.option('--negate', '-n', required=False, default=False,
              show_default=True, type=bool,
              help="Discard all sequences aligning to the database "
                   "passed via --ref-fp option")
@click.option('--threads-per-sample', '-a', required=False, type=int,
              default=1, show_default=True,
              help="Number of threads to use per sample")
@click.option('--delim', required=False, type=str, default='_',
              show_default=True, help="Delimiter in FASTA labels to separate "
                                      "sample ID from sequence ID")
@click.option('--keep-tmp-files', required=False, type=bool, default=False,
              show_default=True,
              help="Keep temporary files (useful for debugging)")
@click.option('--no-split', required=False, type=bool, default=False,
              show_default=True,
              help="Skip the split fasta to files step. Assumes seqs_fp "
                   "is a directory of fasta files (one per sample)")
#@click.option('-A', required=False, type=bool, default=False,
#              help="ATTACK MODE (http://xkcd.com/1692)")
def workflow(seqs_fp, output_dir, ref_fp, ref_db_fp, overwrite,
             read_error, mean_error, error_dist, indel_prob, indel_max,
             trim_length, min_size, negate, threads_per_sample, delim,
             keep_tmp_files, no_split):
    """Launch deblur workflow"""
    logger = logging.getLogger(__name__)
    logger.info('deblur workflow started on file %s' % seqs_fp)
    # If the user provided an error_dist value, we map it to a list of floats
    if error_dist:
        error_dist = list(map(float, error_dist.split(',')))
    # Create output directory
    if exists(output_dir):
        if overwrite:
            rmtree(output_dir)
        else:
            logger.critical('output directory %s already exists' % output_dir)
            raise OSError("Output directory already exists. Choose a "
                          "different directory or use option --overwrite True"
                          "(-w True)")
    working_dir = join(output_dir, "deblur_working_dir")
    makedirs(working_dir)

    # Split demultiplexed FASTA on sample IDs
    if not no_split:
        out_dir_split = join(output_dir, "split")
        logger.info('splitting file %s to per sample fasta. '
                    'output %s' % (seqs_fp, out_dir_split))
        mkdir(out_dir_split)
        with open(seqs_fp, 'U') as seqs_f:
            split_sequence_file_on_sample_ids_to_files(
                seqs_f,
                out_dir_split)
    else:
        logger.info('processing directory %s' % seqs_fp)
        out_dir_split = seqs_fp

    # Build SortMeRNA indexes
    files_to_remove = []
    if not ref_db_fp:
        logger.info('building sortmerna index files')
        ref_db_fp = build_index_sortmerna(
            ref_fp=ref_fp,
            working_dir=working_dir)
    all_bioms = []

    # Create OTU table per sample
    logger.info('processing per sample fasta files')
    for fn in listdir(out_dir_split):
        input_fp = join(out_dir_split, fn)
        if isfile(input_fp):
            biom_fp = launch_workflow(
                seqs_fp=input_fp, working_dir=working_dir,
                read_error=read_error, mean_error=mean_error,
                error_dist=error_dist, indel_prob=indel_prob,
                indel_max=indel_max, trim_length=trim_length,
                min_size=min_size, ref_fp=ref_fp, ref_db_fp=ref_db_fp,
                negate=negate, threads_per_sample=threads_per_sample, delim=delim)
            if biom_fp:
                all_bioms.append(biom_fp)
    logger.info('finished processing per sample fasta files')

    # Merge chimera cleaned fasta files to a single biom table
    output_filename = 'final.biom'
    output_fp = join(output_dir, output_filename)

    samples = get_files_for_table(working_dir)
    create_otu_table(output_fp, samples)

    # Clean up
    if not keep_tmp_files:
        logger.warn('Cleaning up temp files')
        remove_files(files_to_remove, error_on_missing=False)
        rmtree(working_dir)
    else:
        logger.warn('Keeping temp files')
    logger.warn('deblur workflow finished')
    logger.warn('output saved to %s' % output_fp)
    logger.warn('------------------')


if __name__ == '__main__':
    deblur_cmds()
